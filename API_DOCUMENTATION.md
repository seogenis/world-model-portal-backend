# World Model Portal API Documentation

This document describes the available API endpoints for interacting with the World Model Portal backend, which provides text-to-video generation services using NVIDIA's Cosmos text-to-video model.

## Table of Contents

- [Base URL](#base-url)
- [User Flow Sequence](#user-flow-sequence)
- [Prompt Management Endpoints](#prompt-management-endpoints)
- [Video Generation Endpoints](#video-generation-endpoints)
- [Batch Processing Endpoints](#batch-processing-endpoints)
- [Static File Paths](#static-file-paths)
- [Session Management](#session-management)
- [Status Codes](#status-codes)
- [Status Values](#status-values)
- [Rate Limiting](#rate-limiting)
- [Error Handling](#error-handling)
- [Frontend Integration Tips](#frontend-integration-tips)

## Base URL

All API endpoints are prefixed with `/api`.

## User Flow Sequence

The typical user flow follows this sequence:

1. **Enhance a rough prompt** (`POST /api/enhance`)
2. **Initialize parameters** (`POST /api/initialize`) 
3. **Generate a single video** (`POST /api/video/single_inference`)
4. **Generate prompt variations** (`POST /api/generate-variations`)
5. **Process batch of videos** (`POST /api/video/batch_inference`)
6. **Update prompt through conversation** (`POST /api/update`)
7. **Generate new videos with refined prompts** (`POST /api/video/single_inference`)
8. **Download batch results** (`GET /api/video/batch_download/{batch_id}`)

## Prompt Management Endpoints

### 1. Enhance Prompt

**Endpoint:** `POST /api/enhance`

Enhance a basic prompt with more descriptive details.

**Request:**
```json
{
  "rough_prompt": "cats playing",
  "session_id": "optional-session-id-string"
}
```

**Response:**
```json
{
  "original_prompt": "cats playing",
  "enhanced_prompt": "Two fluffy tabby cats playfully chasing each other through a sunlit living room, their paws batting at colorful toy mice",
  "session_id": "generated-or-provided-session-id"
}
```

### 2. Initialize Prompt

**Endpoint:** `POST /api/initialize`

Initialize the system with a new prompt for refinement.

**Request:**
```json
{
  "prompt": "A colorful sunset over the ocean",
  "session_id": "optional-session-id-string"
}
```

**Response:**
```json
{
  "parameters": {
    "time": "sunset",
    "scene": "ocean",
    "colors": ["orange", "red", "purple"],
    "additional_parameters": "..."
  },
  "prompt": "A colorful sunset over the ocean",
  "changes": [],
  "session_id": "generated-or-provided-session-id"
}
```

### 3. Update Prompt

**Endpoint:** `POST /api/update`

Update the prompt based on a natural language request.

**Request:**
```json
{
  "user_request": "Make it more dramatic with stormy clouds",
  "session_id": "your-session-id"
}
```

**Response:**
```json
{
  "parameters": {
    "time": "sunset",
    "scene": "ocean",
    "weather": "stormy",
    "sky": "dramatic clouds",
    "additional_parameters": "..."
  },
  "prompt": "A dramatic sunset over the stormy ocean with dark clouds gathering on the horizon",
  "changes": [
    "Added stormy weather",
    "Made sky more dramatic with clouds"
  ],
  "session_id": "your-session-id"
}
```

### 4. Generate Variations

**Endpoint:** `POST /api/generate-variations`

Generate variations of selected prompts from history. This endpoint will always return exactly the number of prompts specified in `total_count`, regardless of how many prompts are selected.

**Request:**
```json
{
  "selected_indices": [0, 2],
  "total_count": 8,
  "session_id": "your-session-id"
}
```

**Response:**
```json
{
  "prompts": [
    "A dramatic sunset over the stormy ocean with lightning strikes illuminating dark clouds",
    "A peaceful sunset over calm ocean waters with gentle waves and seagulls flying overhead",
    "A vibrant sunset over a tropical ocean with palm trees silhouetted against the colorful sky",
    "A misty sunset over a rocky coastline with waves crashing against the shore",
    "A sunset over an arctic ocean with icebergs reflecting orange and purple hues",
    "A sunset over a bustling harbor with silhouettes of boats against the orange sky",
    "A dramatic sunset over the ocean with a distant sailboat on the horizon",
    "A sunset over a pristine beach with footprints in the sand leading to the water"
  ],
  "selected_indices": [0, 2],
  "session_id": "your-session-id"
}
```

**Important Notes:**
- This endpoint is guaranteed to always return exactly `total_count` prompts
- If insufficient variations are generated by the AI, the system will use fallback mechanisms to reach the requested count
- Some prompts may be marked as fallbacks or duplicates in cases where generation is challenging

### 5. Get Prompt History

**Endpoint:** `POST /api/history`

Get the history of all prompts created in the specified session.

**Request:**
```json
{
  "session_id": "your-session-id"
}
```

**Response:**
```json
{
  "history": [
    {
      "prompt": "A colorful sunset over the ocean",
      "parameters": {
        "time": "sunset",
        "scene": "ocean",
        "colors": ["orange", "red", "purple"]
      },
      "description": "Initial prompt"
    },
    {
      "prompt": "A dramatic sunset over the stormy ocean with dark clouds gathering on the horizon",
      "parameters": {
        "time": "sunset",
        "scene": "ocean",
        "weather": "stormy",
        "sky": "dramatic clouds"
      },
      "description": "Added storm effects"
    }
  ],
  "session_id": "your-session-id"
}
```

### 6. Get Current Parameters

**Endpoint:** `POST /api/parameters`

Get the current parameters extracted from the active prompt for a specific session.

**Request:**
```json
{
  "session_id": "your-session-id"
}
```

**Response:**
```json
{
  "parameters": {
    "time": "sunset",
    "scene": "ocean",
    "weather": "stormy",
    "sky": "dark clouds",
    "additional_parameters": "..."
  },
  "session_id": "your-session-id"
}
```

## Video Generation Endpoints

### 1. Generate Single Video

**Endpoint:** `POST /api/video/single_inference`

Generates a single video from a text prompt.

**Request:**
```json
{
  "prompt": "A beautiful sunrise over a mountain lake with reflections in the water"
}
```

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": "Video generation started. Check status endpoint for updates."
}
```

### 2. Get Single Video Status

**Endpoint:** `GET /api/video/status/{job_id}`

Get the current status of a single video generation job.

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "generating",
  "message": "Generating video from prompt",
  "progress": 65,
  "video_url": null
}
```

### 3. Get Video File

**Endpoint:** `GET /api/videos/{video_id}`

Retrieve a generated video file by its ID.

**Response:** The video file (MP4 format).

## Batch Processing Endpoints

### 1. Generate Multiple Videos (Batch)

**Endpoint:** `POST /api/video/batch_inference`

Generates multiple videos in parallel, each on a different GPU.

**Request:**
```json
{
  "prompts": [
    "A sunset over the ocean with waves crashing on the shore",
    "A bustling city street at night with neon lights",
    "A spaceship landing on an alien planet",
    "A forest with sunlight streaming through the trees"
  ]
}
```

**Response:**
```json
{
  "batch_id": "662e8400-e29b-41d4-a716-446655440123",
  "message": "Batch processing started for 4 prompts. Check batch_status endpoint for updates."
}
```

### 2. Get Batch Status

**Endpoint:** `GET /api/video/batch_status/{batch_id}`

Get the current status of all videos in a batch.

**Response:**
```json
{
  "batch_id": "662e8400-e29b-41d4-a716-446655440123",
  "status": "processing",
  "total": 4,
  "completed": 1,
  "failed": 0,
  "message": "Completed: 1/4",
  "jobs": [
    {
      "job_id": "job_0",
      "status": "complete",
      "message": "Video generation complete",
      "progress": 100,
      "video_url": "/api/videos/662e8400-e29b-41d4-a716-446655440123/job_0/job_0.mp4",
      "gpu_id": 0,
      "prompt": "A sunset over the ocean with waves crashing on the shore"
    },
    {
      "job_id": "job_1",
      "status": "generating",
      "message": "Generating video from prompt",
      "progress": 75,
      "video_url": null,
      "gpu_id": 1,
      "prompt": "A bustling city street at night with neon lights"
    },
    {
      "job_id": "job_2",
      "status": "pending",
      "message": "Job is queued and waiting to start",
      "progress": 0,
      "video_url": null,
      "gpu_id": 2,
      "prompt": "A spaceship landing on an alien planet"
    },
    {
      "job_id": "job_3",
      "status": "pending",
      "message": "Job is queued and waiting to start",
      "progress": 0,
      "video_url": null,
      "gpu_id": 3,
      "prompt": "A forest with sunlight streaming through the trees"
    }
  ]
}
```

### 3. Download Batch Videos as ZIP

**Endpoint:** `GET /api/video/batch_download/{batch_id}`

Download all successfully generated videos from a batch as a ZIP file.

**Response:** A ZIP file containing all generated videos.

## Static File Paths

The system stores generated videos in a consistent file structure that can be accessed directly:

### Single Video Paths

- Standard path: `/static/videos/{job_id}/video.mp4`
- Example: `/static/videos/550e8400-e29b-41d4-a716-446655440000/video.mp4`
- When a video generation is complete, the `video_url` field in the status response will provide the direct path

### Batch Video Paths

- Standard path: `/static/videos/{batch_id}/{job_id}/video.mp4` 
- Example: `/static/videos/662e8400-e29b-41d4-a716-446655440123/job_0/video.mp4`
- Each job in the batch status response includes its own `video_url` when complete

### Fallback Mechanisms

If the standard video paths don't work, the system checks several locations:
- Legacy format: `/static/videos/{job_id}.mp4`
- API endpoint access: `/api/videos/{video_id}` (handles all file location patterns)
- Batch downloads: `/api/video/batch_download/{batch_id}` (returns all videos as ZIP)

## Frontend Integration Tips

### Displaying Videos

1. **Direct embedding**: Use the `video_url` from status responses
   ```html
   <video src="/static/videos/550e8400-e29b-41d4-a716-446655440000/video.mp4" controls></video>
   ```

2. **Fallback pattern**: Handle missing video URLs
   ```javascript
   const videoUrl = statusData.video_url || `/static/videos/${jobId}/video.mp4`;
   videoElement.src = videoUrl;
   ```

3. **Efficient polling**: Implement exponential backoff when checking status
   ```javascript
   // Start with 1-2 second interval, gradually increase to max 10-15 seconds
   const interval = Math.min(baseInterval * Math.pow(1.1, pollCount), maxInterval);
   ```

4. **Batch display**: Show a grid of videos from batch processing
   ```javascript
   batchData.jobs.forEach(job => {
     if (job.status === 'complete' && job.video_url) {
       // Display video using job.video_url
     }
   });
   ```

## Session Management

### 1. List Active Sessions

**Endpoint:** `GET /api/sessions`

List all active sessions with their last access times.

**Response:**
```json
{
  "sessions": {
    "session-id-1": 1717027814.5678,
    "session-id-2": 1717027885.1234,
    "session-id-3": 1717027900.9876
  }
}
```

### 2. Delete Session

**Endpoint:** `DELETE /api/session/{session_id}`

Delete a specific session and its associated data.

**Response:**
```json
{
  "message": "Session session-id-1 deleted successfully"
}
```

## Session Management Details

All prompt-related endpoints support session-based state management:

- Sessions are created automatically when not provided
- Session IDs should be included in the request body for each call after initial creation
- Session data persists across API calls
- All sessions expire after 1 hour of inactivity (configurable)
- Session creation is rate-limited to 10 sessions per minute per IP

## Status Codes

- `200 OK`: Request successful
- `400 Bad Request`: Invalid request parameters
- `404 Not Found`: Resource not found
- `429 Too Many Requests`: Rate limit exceeded (NVIDIA API or session creation)
- `500 Internal Server Error`: Server error

## Status Values

### Single Video Status

- `pending`: Job is queued or waiting to start
- `generating`: Video generation in progress on NVIDIA API
- `processing`: Local processing of video files (extracting from zip)
- `complete`: Video generation complete
- `failed`: Video generation failed

### Batch Status

- `processing`: Batch is currently being processed
- `complete`: All jobs in batch completed successfully
- `partial`: Some jobs completed, some failed
- `failed`: All jobs in batch failed
- `not_found`: Batch ID not found

## Rate Limiting

- **NVIDIA API**: Limited to 1 concurrent request per API key
- **Session Creation**: Limited to 10 sessions per minute per IP address
- **Background Processing**: Limited by available GPUs (defaults to 8)

## Error Handling

API errors follow standard HTTP status codes with descriptive messages. Common errors include:

- **NVIDIA API Authentication**: Check API key configuration
- **Rate Limiting**: Wait and retry with exponential backoff
- **Missing Session**: Initialize a prompt first
- **Invalid Parameters**: Check request format and parameters
- **Resource Not Found**: Verify IDs for videos, batches, and sessions

For robust applications, implement:
- Proper error handling for all API calls
- Polling with appropriate intervals for status updates
- Exponential backoff for retrying failed operations